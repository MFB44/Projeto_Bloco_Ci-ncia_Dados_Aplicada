import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup as bs

st.set_page_config(page_title='FieldGuide', page_icon='üìö', layout='centered', initial_sidebar_state='auto')

st.sidebar.header("Bem-vindo ao FieldGuide!")
st.sidebar.image("https://i.imgur.com/mlvt8or.png", use_column_width=True)
st.sidebar.write("### Selecione a p√°gina desejada:")
page = st.sidebar.selectbox("", ["Introdu√ß√£o (TP1)","Dados (TP2)", "BeautifulSoup (TP2)", "TP3 - Selenium, FastAPI, LLM"])

@st.cache_data
def read_csv(file):
    data = pd.read_csv(file, sep=';')
    return data

if page == "Introdu√ß√£o (TP1)":
    st.image("https://i.imgur.com/9SCBoG5.png", width=650)
    st.markdown("# Field Guide")
    st.markdown("## O Guia de Campo para sua Carreira")

    st.write("")

    st.write("Aplica√ß√£o que acumula todas as informa√ß√µes para te ajudar a planejar sua vida profissional, mostrando cargos, habilidades necess√°rias para exerc√™-los e cursos superiores.")
    st.write("Este projeto procura ajudar principalmente alunos do Ensino M√©dio, que assim como eu, estavam confusos com seu futuro e ficaram dias procurando informa√ß√µes sobre suas poss√≠veis carreiras futuras.")
    st.write("Nele voc√™ entra e pesquisa por uma proffis√£o e encontra tudo que voc√™ pode precisar para trabalhar na √°rea.")

    st.image(r"app\data\Beige Modern Chic Business Model Canvas Brainstorm.png")
    st.image(r"app\data\Project Charter - Projeto Bloco Ci√™ncia de Dados Aplicada-1.png")

    st.markdown("### Links:")
    st.markdown("#### Inspira√ß√£o Principal")
    st.write("[Mapa de Carreiras](https://www.vagas.com.br/mapa-de-carreiras/)")
    st.markdown("#### Poss√≠veis Fontes de Dados")
    st.write("[API Feed de Vagas](https://apifeeddevagas.docs.apiary.io/#reference/0/feed-de-vagas/feed-de-vagas)")
    st.write("[Cadastro Nacional de Cursos Superiores](https://emec.mec.gov.br/emec/nova)")
    st.write("[API Profiss√µes](https://api.sienge.com.br/docs/html-files/professions-v1.html#/)")
    st.write("[Tabela de Pontos Sisu](https://www.guiadacarreira.com.br/blog/tabela-de-pontos-do-enem-para-cada-curso)")
    st.write("[Catho](https://www.catho.com.br/vagas/)")
    st.write("[Vagas.com](https://www.vagas.com.br)")

    file = (r'app\data\relatorio_consulta_publica_avancada_curso_25_08_2024_00_05_33.csv')
    data = read_csv(file)

    st.markdown("### Exemplo de tabela de dados:")
    st.write("O exemplo a seguir utiliza uma tabela vinda do site citado acima (Cadastro Nacional de Cursos Superiores), ela mostra apenas cursos de 'Dados' e os dados n√£o foram tratados, portanto h√° diversas colunas que n√£o ser√£o utilizadas no projeto final. Eu pretendo ampliar estes dados para todo o Brasil e utilizar APIs, por√©m ainda n√£o consegui fazer funcionar mas estou trabalhando em me capacitar para tal.")
    dataframe = st.dataframe(data)

if page == "Dados (TP2)":
    st.title("Dados Relat√≥rio Consulta P√∫blica Avan√ßada Curso")
    file = (r'app\data\relatorio_consulta_publica_avancada_curso_25_08_2024_00_05_33.csv')
    data = read_csv(file)
    dataframe = st.dataframe(data)
    if 'complete' not in st.session_state:
        st.session_state['complete'] = dataframe
    st.download_button(
        label="Baixar dados completos",
        data=data.to_csv(index=False).encode('utf-8'),
        file_name='dados_completos.csv',
        mime='text/csv'
    )
    cols = list(data.columns)
    colunas = st.multiselect("Mostrar colunas", cols)
    if colunas:
        display = data[colunas]
        if 'multi' not in st.session_state:
            st.session_state['multi'] = display
        st.write(display)
        st.download_button(
            label="Baixar dados",
            data=display.to_csv(index=False).encode('utf-8'),
            file_name='dados.csv',
            mime='text/csv'
        )

    uploaded_file = st.file_uploader("Escolha um arquivo", type=["csv", "xlsx", "json"])
    if uploaded_file is not None:
        file_type = uploaded_file.name.split('.')[-1]
        if file_type == 'csv':
            data_u = pd.read_csv(uploaded_file)
        elif file_type == 'xlsx':
            data_u = pd.read_excel(uploaded_file)
        elif file_type == 'json':
            data_u = pd.read_json(uploaded_file)
        else:
            st.error("Tipo de arquivo n√£o suportado!")
            data_u = None
        
        if data_u is not None:
            st.dataframe(data_u)
            st.download_button(
                label="Baixar dados Upload",
                data=data_u.to_csv(index=False).encode('utf-8'),
                file_name='uploaded.csv',
                mime='text/csv'
            )
            if 'uploaded' not in st.session_state:
                st.session_state['uploaded'] = data_u

if page == "BeautifulSoup (TP2)":
    st.title("Aqui voc√™ pode encontrar todas as profiss√µes dispon√≠veis no site Quero Bolsa, organizadas por letra.")
    HEADER = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',
    }
    resp = requests.get("https://querobolsa.com.br/carreiras-e-profissoes/todas", headers=HEADER, timeout=30)
    soup = bs(resp.content, 'html.parser')
    profissoes = soup.find_all('a', class_='z-link')
    profs = []
    for profissao in profissoes:
        profs.append(profissao.text)

    profs_at = profs[50:955]
    profs_at = [prof.strip().replace('\n', '') for prof in profs_at]
    for element in profs_at:
        if element == '':
            profs_at.remove(element)
    alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']
    
    sel_let = st.selectbox("Profiss√µes por letra", alphabet)
                   
    st.markdown("---")
    st.markdown("#### (Role para ver todas)")
    st.markdown(
        f"<div style='height: 300px; overflow-y: scroll; border: 1px solid #ccc; padding: 10px;'>{''.join([f'<p>{prof}</p>' for prof in profs_at if prof[0] == sel_let])}</div>",
        unsafe_allow_html=True
    )
    st.download_button(
        label="Baixar profiss√µes",
        data='\n'.join(profs_at).encode('utf-8'),
        file_name='profiss√µes.txt',
        mime='text/plain'
    )

    profs_at = profs_at
    if 'professions' not in st.session_state:
        st.session_state['professions'] = profs_at
    with open(r'app\data\professions.txt','w') as f:
        for item in profs_at:
            f.write(item + '\n')
            
if page == "TP3 - Selenium, FastAPI, LLM":
    st.title("TP3 - Selenium, FastAPI, LLM")
    st.write("Esta parte do trabalho n√£o √© t√£o grande quanto as √∫ltimas. N√£o obtive √™xito ap√≥s testar em alguns sites diferentes, por√©m quero demonstrar que tenho interesse em utiliz√°-lo para coletar dados de sites como 'vagas.com.br' e 'catho.com.br'.")
    st.write("Com isso eu poderia coletar dados de vagas de emprego e sal√°rios, por exemplo, e disponibilizar para o usu√°rio juntamente dos cursos. Com isto, j√° correlaciono ao uso de IA, possivelmente fazendo textos que explicam detalhes e como se relacionam cada vaga com certos cursos.")
    st.write("Com o conhecimento que ganharei neste trimestre e com o que j√° aprendi, pretendo fazer um projeto mais robusto e completo, com mais funcionalidades e informa√ß√µes.")
    st.write("Sobre o FastAPI, eu n√£o consegui implementar nada ainda, mas pretendo utiliz√°-lo para criar uma API que disponibilize todos dados que coletarei.")
    st.write("Esperava fazer mais nesta etapa mas apenas tive uma aula sobre as funcionalidades da FastAPI e n√£o pratiquei com Selenium mas a proposta de neg√≥cio est√° mais clara para mim e estou mais confiante para fazer um projeto mais completo.")
    st.write("Novas pastas foram inclusas ('FastAPI' e 'Selenium' na pasta 'services') com os prot√≥tipos de c√≥digo que eu pretendo utilizar.")
    st.write("Exemplos de como demonstrar dados no projeto tirados do Mapa VAGAS de Carreiras:")

    col1, col2 = st.columns(2)
    with col1:
        st.image('https://i.imgur.com/Y5wA5nY.png')
    with col2:
        st.image('https://i.imgur.com/x0q8RvQ.png')